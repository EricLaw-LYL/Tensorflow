{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config of GPU\n",
    "Not running this part becase I am only using CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape the dataset\n",
    "- turn 28x28 square to 1x784 vector\n",
    "- normalize the data between 0 and 1, in order to train faster (1 channel, 255 grey scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 28*28).astype(\"float32\") / 255.0\n",
    "x_test = x_test.reshape(-1, 28*28).astype(\"float32\") / 255.0\n",
    "# -1 means use the original size\n",
    "\n",
    "# change numpy array to tensor: (not necessary)\n",
    "# x_train = tf.convert_to_tensor(x_train)\n",
    "# x_test = tf.convert_to_tensor(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential API\n",
    "Very convenient, not very flexible  \n",
    "Basically one input -> one output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1850 - accuracy: 0.9434\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0786 - accuracy: 0.9756\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0540 - accuracy: 0.9832\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0417 - accuracy: 0.9869\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0318 - accuracy: 0.9897\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0268 - accuracy: 0.9918\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0249 - accuracy: 0.9920\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0197 - accuracy: 0.9935\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0189 - accuracy: 0.9941\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0163 - accuracy: 0.9945\n",
      "Model evaluation:\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1008 - accuracy: 0.9790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10076961666345596, 0.9789999723434448]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        Input(shape = 28*28), \n",
    "        layers.Dense(512, activation = \"relu\"), \n",
    "        layers.Dense(256, activation = \"relu\"), \n",
    "        layers.Dense(10, activation = \"softmax\"), \n",
    "    ]\n",
    ")\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(\n",
    "    loss = losses.SparseCategoricalCrossentropy(from_logits = False), \n",
    "    optimizer = optimizers.Adam(lr = 0.001), # lr: learning rate\n",
    "    metrics = [\"accuracy\"], \n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, batch_size = 32, epochs = 10, verbose = 1)\n",
    "\n",
    "print(\"Model evaluation:\")\n",
    "model.evaluate(x_test, y_test, batch_size = 32, verbose = 1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f7f4d3cdfe853d1c63656e19bc645d602c2164740def1398a3f264873f06abaa"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('nlp-3.9': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
